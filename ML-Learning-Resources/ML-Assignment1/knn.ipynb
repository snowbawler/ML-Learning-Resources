{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project 1: K-Nearest Neighbor (KNN)\n",
    "In this assignment, you are going to practice cleaning a dataste and implement one of the basic ML algorithms called K-Nearest Neighbors. Although KNN is not the most powerful algorithm, it is quite fast and is still used when we have a small dataset. If you haven't already, read about the algorithm for KNN [here](https://www.ibm.com/topics/knn#:~:text=The%20k%2Dnearest%20neighbors%20algorithm%2C%20also%20known%20as%20KNN%20or,of%20an%20individual%20data%20point.).\n",
    "\n",
    "You will be working with a heart disease dataset where each row represents a person and the columns contain information that person's health. The very last column of each contains a binary label (either 0 or 1) that indicates whether a person has heart disease or not. Your job is to create a KNN algorithm that can predict whether a person has heart disease or not based on their health features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Features: (918, 11)\n",
      "Dimensions of Labels: (918,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "heart_data = pd.read_csv('data/heart.csv')\n",
    "\n",
    "# Separates the data into features and labels\n",
    "features = heart_data.drop('HeartDisease', axis=1) \n",
    "labels = heart_data['HeartDisease']\n",
    "\n",
    "print(\"Dimensions of Features:\",  features.shape)\n",
    "print(\"Dimensions of Labels:\", labels.shape)\n",
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Find all the features that are categorical (i.e. not numerical), remove them from the feature matrix, and then convert the Pandas dataframe into a Numpy Array. You can call this modified set of features `numerical_features`. The `drop` function in pandas is useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.to_numpy of      Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  HeartDisease\n",
      "0     40        140          289          0    172      0.0             0\n",
      "1     49        160          180          0    156      1.0             1\n",
      "2     37        130          283          0     98      0.0             0\n",
      "3     48        138          214          0    108      1.5             1\n",
      "4     54        150          195          0    122      0.0             0\n",
      "..   ...        ...          ...        ...    ...      ...           ...\n",
      "913   45        110          264          0    132      1.2             1\n",
      "914   68        144          193          1    141      3.4             1\n",
      "915   57        130          131          0    115      1.2             1\n",
      "916   57        130          236          0    174      0.0             1\n",
      "917   38        138          175          0    173      0.0             0\n",
      "\n",
      "[918 rows x 7 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Code goes here\n",
    "numerical_features = features.drop(columns=['Sex','ChestPainType','RestingECG','ExerciseAngina','ST_Slope']).to_numpy\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Splitting into training and test\n",
    "\n",
    "First, we need to split the data into a training and testing set. Implement a function `split_data` that splits the dataset into a training set and test set. For this example, we will train on around 60% of the dataset and test on the other 40% (the proportions may not be exact but you can round to the nearest integer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(features, labels):\n",
    "    \"\"\"\n",
    "    This function splits the data into training and testing sets.\n",
    "\n",
    "    Args:\n",
    "        features (pandas.DataFrame): The dataframe containing the features.\n",
    "        labels (pandas.DataFrame): The dataframe containing the labels.\n",
    "    Returns:\n",
    "        (tuple): A tuple containing the training features, training labels, test features, and test labels.\n",
    "    \"\"\"\n",
    "    train_features = None\n",
    "    train_labels = None\n",
    "    test_features = None\n",
    "    test_labels = None\n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "Implement the function `knn` that takes in a feature matrix along with an array of labels and outputs an array of predictions. Then, implement a function `accuracy` which computes the accuracy of your predictions. Finally, run the `knn` function using just the numerical features and print the accuracy.\n",
    "\n",
    "Remember in the KNN algorithm we classify a test point by finding the top $k$ training points that are closest to that point and the choosing the most frequent label out of the labels of those $k$ training points. We will be using **Euclidean distance** as the distance metric between two feature vectors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(train_features, train_labels, test_features, k=2):\n",
    "    \"\"\"\n",
    "    This function takes in a training set and a test set and returns predictions for the model\n",
    "\n",
    "    Args:\n",
    "        - train_features: A numpy array of training features\n",
    "        - train_labels: A numpy array of training labels\n",
    "        - test_features: A numpy array of test features\n",
    "        - k: The number of nearest neighbors to use in the prediction\n",
    "    Returns:\n",
    "        - A numpy array of predictions\n",
    "    \"\"\"\n",
    "    return\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    \"\"\"\n",
    "    This function takes in a set of predictions and labels and returns the accuracy of the model\n",
    "\n",
    "    Args:\n",
    "        - predictions: A numpy array of predictions\n",
    "        - labels: A numpy array of labels\n",
    "    Returns:\n",
    "        - The accuracy of the model\n",
    "    \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Normalization\n",
    "We ran the model above just to show you how the model would do initially. In real world cases, we would normalize each feature in the dataset such that the max value in the dataset of each feature is $1$ and the minimum value of each feature is $0$. To do this, if the feature we want to [normalize](https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization)) is $x_i$ we replace it with a value $z_i$ as shown below (note $\\max$ and $\\min$ are the max and min values of $x_i$ per data point).\n",
    "\n",
    "$$z_i = \\frac{x_i - min(x_i)}{max(x_i) - min(x_i)}$$\n",
    "\n",
    "Implement the function `normalize` which carries out the above operation one feature variable (i.e. one column of the dataset), then apply it to each column of your feature matrix, and calculuate the accuracy of your knn model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(feat):\n",
    "    \"\"\"\n",
    "    This function takes in a feature and returns a normalized version of the feature\n",
    "\n",
    "    Args:\n",
    "        - feat: A numpy array of features\n",
    "    Returns:\n",
    "        - A numpy array of normalized features\n",
    "    \"\"\"\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Adding in the Categorical Features\n",
    "We are now going to try to add in the categorical features to see if the algorithm improves. The way we will add in categorical features is by [one-hot encoding](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f) them. For example, if there a categorical variable that has $c$ classes, you will turn it into a vector of length $c$ where the $i$th element corresponds to the $i$th class. For each data point, all the elements are $0$ except for the element corresponding to that data point's class.\n",
    "\n",
    "You will implement a function `one_hot` that converts a categorical feature vector into a one-hot encoding and then apply that function to each categorical variable. Then, calculate the accuracy of your knn model when you are using the categorical features in addition to the numerical features (Note you can either make `one_hot` operate on a Pandas dataframe or a numpy array. Of course, this will affect other parts of your implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(cat_feature):\n",
    "    \"\"\"\n",
    "    This function takes in a categorical feature and returns a one-hot encoded version of the feature.\n",
    "\n",
    "    Args:\n",
    "        - cat_feature: the of categorical features\n",
    "    Returns:\n",
    "        - A one-hot encoded version of the feature\n",
    "    \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Hyperparameter Tuning\n",
    "The value of $k$ that works best for our dataset. This is known as hyperparameter tuning. Run the KNN model for all the integer values of k in the interval $1 \\leq k \\leq 200$, compute the accuracy of each model, and then make a line graph of the training and testing accuracy versus the value of $k$. If you need a refresher making a line graph with matplotlib, look [here](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html). \n",
    "\n",
    "**Describe what how you see the training and testing accuracy change as $k$ changes**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Weighted KNN\n",
    "\n",
    "We can improve our KNN algorithm by changing the how much each neighbor contributes to the final prediction based on the distance of each neighbor from the test point. Try to make an implementation of KNN that assigns a weight $w_i$ to each neighbor based on the distance\n",
    "\n",
    "$$w_i = \\frac{1}{d^2}$$\n",
    "\n",
    "where $d$ is the Euclidean distance from the test point and $i$th neighbor. To make the final prediction, you will sum up all the weights where neighbors had a negative label (i.e. no heart disease) and do the same for the neighbors with the positive label (i.e. there is heart disease). Then, you will choose the label that has the greater sum of weights as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('alberta')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a6660d5f06cd4e5b96ba351b7d6a1f66229626bb32b6ef5591065b69c3883e6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
